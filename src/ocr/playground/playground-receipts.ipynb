{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Rough Work"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. ## Reading receipts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pytesseract\n",
    "import cv2\n",
    "from PIL import Image\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "2. ## Manipulating data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "file_path = f\"{os.getcwd()}/test_files/receipt1.jpeg\"\n",
    "\n",
    "image = cv2.imread(file_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tempfile\n",
    "import cv2  \n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "\n",
    "def deskew(image):\n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    _, binary = cv2.threshold(gray, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)\n",
    "    coords = np.column_stack(np.where(binary > 0))\n",
    "    contour_points = [tuple(coord) for coord in coords]\n",
    "    rect = cv2.minAreaRect(np.array(contour_points))\n",
    "    angle = rect[-1]\n",
    "    if angle < -45:\n",
    "        angle = -(90 + angle)\n",
    "    else:\n",
    "        angle = -angle\n",
    "    (h, w) = image.shape[:2]\n",
    "    center = (w // 2, h // 2)\n",
    "    M = cv2.getRotationMatrix2D(center, angle, 1.0)\n",
    "    rotated = cv2.warpAffine(image, M, (w, h), flags=cv2.INTER_CUBIC, borderMode=cv2.BORDER_REPLICATE)\n",
    "    return rotated\n",
    "\n",
    "def set_image_dpi(image, output_file_path):\n",
    "    im = Image.fromarray(image)\n",
    "    length_x, width_y = im.size\n",
    "    factor = min(1, float(1024.0 / length_x))\n",
    "    size = int(factor * length_x), int(factor * width_y)\n",
    "    im_resized = im.resize(size, Image.ANTIALIAS)\n",
    "    im_resized.save(output_file_path, dpi=(300, 300))\n",
    "    return output_file_path\n",
    "\n",
    "def remove_noise(image):\n",
    "    return cv2.fastNlMeansDenoisingColored(image, None, 10, 10, 7, 15)\n",
    "\n",
    "def get_grayscale(image):\n",
    "    return cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "def thresholding(image):\n",
    "    return cv2.threshold(image, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)[1]\n",
    "\n",
    "def proceaa_image(image):\n",
    "    deskewed_image = deskew(image)\n",
    "    noise_removed_image = remove_noise(deskewed_image)\n",
    "    grayscale_image = get_grayscale(noise_removed_image)\n",
    "    thresholded_image = thresholding(grayscale_image)\n",
    "    return thresholded_image\n",
    "# Read the image\n",
    "file_path = f\"{os.getcwd()}/test_files/receipt1.jpeg\"\n",
    "image = cv2.imread(file_path)\n",
    "\n",
    "# Process the image\n",
    "processed_image = proceaa_image(image)\n",
    "\n",
    "# Save the processed image\n",
    "output_file_path = f\"{os.getcwd()}/test_files/output1.jpeg\"\n",
    "cv2.imwrite(output_file_path, processed_image)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <ins>Image Processing</ins>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "import PIL as image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = f\"{os.getcwd()}/test_files/receipt3.jpeg\"\n",
    "output_file_path = f\"{os.getcwd()}/test_files/output.jpeg\"\n",
    "img = cv2.imread(file)\n",
    "pilimg = Image.open(file)\n",
    "\n",
    "\n",
    "def cv_save(file_path,image):\n",
    "    file = f\"{os.getcwd()}/{file_path}\"\n",
    "    return cv2.imwrite(file, image)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Inverted Images\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Thi is not necessary in tesseract 4'"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inverted_img = cv2.bitwise_not(img)\n",
    "cv2.imwrite(output_file_path,img=inverted_img)\n",
    "\n",
    "'''Thi is not necessary in tesseract 4'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Rescaling\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Binarization\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def grey_scale(image):\n",
    "    \"\"\"\n",
    "    Convert the image to greyscale.\n",
    "    \"\"\"\n",
    "    return cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "img = cv2.imread(file)\n",
    "\n",
    "\n",
    "gray_image = grey_scale(inverted_img)\n",
    "\n",
    "\n",
    "\n",
    "cv2.imwrite(f\"{os.getcwd()}/test_files/grey_scale.jpeg\",gray_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "thresh,im_bw = cv2.threshold(gray_image,200,230,cv2.THRESH_BINARY)\n",
    "\n",
    "cv2.imwrite(f'{os.getcwd()}/test_files/bw.jpg', im_bw)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Noise Removal\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "def noise_removal(imag):\n",
    "    # noise removal\n",
    "    kernel = np.ones((1,1),np.uint8)\n",
    "    image = cv2.dilate(imag,kernel,iterations=1)\n",
    "    kernel = np.ones((1,1),np.uint8)\n",
    "    image = cv2.erode(image, kernel, iterations=1)\n",
    "    image = cv2.morphologyEx(image, cv2.MORPH_CLOSE, kernel)\n",
    "    image = cv2.medianBlur(image, 3)\n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "no_noise = noise_removal(im_bw)\n",
    "cv_save('/test_files/noise.jpg',no_noise)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " \n",
      "\n",
      "”\n",
      "\f\n"
     ]
    }
   ],
   "source": [
    "image = Image.open(f\"{os.getcwd()}/test_files/bw.jpg\")\n",
    "text = pytesseract.image_to_string(image)\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Dilation and Erosion\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "def thin_font(image):\n",
    "    image = cv2.bitwise_not(image)\n",
    "    kernel = np.ones((2, 2), np.uint8)\n",
    "    image = cv2.erode(image, kernel, iterations=1)\n",
    "    image = cv2.bitwise_not(image)\n",
    "    return image\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "erroded = thin_font(no_noise)\n",
    "cv_save(\"test_files/erroded.jpeg\",erroded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "def thick_font(image):\n",
    "    image = cv2.bitwise_not(image)\n",
    "    kernel = np.ones((1, 1), np.uint8)\n",
    "    image = cv2.dilate(image, kernel, iterations=1)\n",
    "    image = cv2.bitwise_not(image)\n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dilated = thick_font(no_noise)\n",
    "cv_save(\"test_files/dilated.jpeg\",dilated)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Rotation / Deskewing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getSkewAngle(cvImage) -> float:\n",
    "    # Prep image, copy, convert to gray scale, blur, and threshold\n",
    "    newImage = cvImage.copy()\n",
    "    gray = cv2.cvtColor(newImage, cv2.COLOR_BGR2GRAY)\n",
    "    blur = cv2.GaussianBlur(gray, (9, 9), 0)\n",
    "    thresh = cv2.threshold(blur, 0, 255, cv2.THRESH_BINARY_INV + cv2.THRESH_OTSU)[1]\n",
    "\n",
    "    # Apply dilate to merge text into meaningful lines/paragraphs.\n",
    "    # Use larger kernel on X axis to merge characters into single line, cancelling out any spaces.\n",
    "    # But use smaller kernel on Y axis to separate between different blocks of text\n",
    "    kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (30, 5))\n",
    "    dilate = cv2.dilate(thresh, kernel, iterations=2)\n",
    "\n",
    "    # Find all contours\n",
    "    contours, hierarchy = cv2.findContours(dilate, cv2.RETR_LIST, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    contours = sorted(contours, key = cv2.contourArea, reverse = True)\n",
    "    for c in contours:\n",
    "        rect = cv2.boundingRect(c)\n",
    "        x,y,w,h = rect\n",
    "        cv2.rectangle(newImage,(x,y),(x+w,y+h),(0,255,0),2)\n",
    "\n",
    "    # Find largest contour and surround in min area box\n",
    "    largestContour = contours[0]\n",
    "    print (len(contours))\n",
    "    minAreaRect = cv2.minAreaRect(largestContour)\n",
    "    cv2.imwrite(\"temp/boxes.jpg\", newImage)\n",
    "    # Determine the angle. Convert it to the value that was originally used to obtain skewed image\n",
    "    angle = minAreaRect[-1]\n",
    "    if angle < -45:\n",
    "        angle = 90 + angle\n",
    "    return -1.0 * angle\n",
    "# Rotate the image around its center\n",
    "def rotateImage(cvImage, angle: float):\n",
    "    newImage = cvImage.copy()\n",
    "    (h, w) = newImage.shape[:2]\n",
    "    center = (w // 2, h // 2)\n",
    "    M = cv2.getRotationMatrix2D(center, angle, 1.0)\n",
    "    newImage = cv2.warpAffine(newImage, M, (w, h), flags=cv2.INTER_CUBIC, borderMode=cv2.BORDER_REPLICATE)\n",
    "    return newImage\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "def deskew(cvImage):\n",
    "    angle = getSkewAngle(cvImage)\n",
    "    return rotateImage(cvImage, -1.0 * angle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "144\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fixed = deskew(img)\n",
    "cv_save(\"test_files/deskewed.jpg\",fixed)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Removing Borders"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Missing Borders\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
